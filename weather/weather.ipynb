{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from ladybug.epw import EPW\n",
    "from ladybug.location import Location\n",
    "from ladybug.sunpath import Sunpath\n",
    "from ladybug_comfort.collection.utci import UTCI\n",
    "from zipfile import ZipFile\n",
    "import geopandas as gpd\n",
    "import ladybug_pandas as lbp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://climate.onebuilding.org/WMO_Region_4_North_and_Central_America/default.html\n",
    "df = gpd.read_file(\n",
    "    \"Region4_USA_TMYx_EPW_Processing_locations.kml\", driver=\"KML\", header=0)\n",
    "df.drop(df[df[\"Description\"] == \"\"].index, inplace=True)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"name\"] = df[\"Name\"]\n",
    "data[\"latitude\"] = df[\"geometry\"].apply(lambda x: x.y)\n",
    "data[\"longitude\"] = df[\"geometry\"].apply(lambda x: x.x)\n",
    "\n",
    "df.head()\n",
    "\n",
    "data[\"url\"] = df[\"Description\"].apply(\n",
    "    lambda x: re.search(\"http.*?\\.zip\", x).group(0))\n",
    "data.drop(data[data[\"url\"].apply(\n",
    "    lambda x: \"TMYx.zip\" not in x)].index, inplace=True)\n",
    "\n",
    "data.index = data[\"url\"].apply(\n",
    "    lambda x: re.search(\".*\\.(.+?)_TMYx\", x).group(1))\n",
    "data.index.name = \"wmo\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "data[\"summer\"] = np.nan\n",
    "data[\"winter\"] = np.nan\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    r = requests.get(row[\"url\"])\n",
    "    zf = ZipFile(BytesIO(r.content))\n",
    "    namelist = zf.namelist()\n",
    "    epw_file = [f for f in namelist if \"epw\" in f][0]\n",
    "    zf.extract(epw_file, \"epws\")\n",
    "    epw_file = row[\"url\"].split(\"/\")[-1].replace(\".zip\", \".epw\")\n",
    "\n",
    "    epw_data = EPW(\"epws/\" + epw_file)\n",
    "    utci = UTCI.from_epw(epw_data, include_wind=True, include_sun=True)\n",
    "\n",
    "    df = pd.Series(utci.is_comfortable.values,\n",
    "                   index=utci.is_comfortable.datetimes)\n",
    "    df.drop(df[df.index.hour < 8].index, inplace=True)\n",
    "\n",
    "    data.loc[i, \"summer\"] = df[\"2017-06-21\":\"2017-09-20\"].mean()\n",
    "    data.loc[i, \"winter\"] = pd.concat(\n",
    "        (df[\"2017-01-01\":\"2017-03-20\"], df[\"2017-12-21\":\"2017-12-31\"])).mean()\n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "data.drop(\"url\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago = data.loc[\"725300\", [\"winter\", \"summer\"]]\n",
    "\n",
    "data[\"winter_score\"] = (data[\"winter\"] / chicago[\"winter\"]).apply(np.log2)\n",
    "data[\"summer_score\"] = (data[\"summer\"] / chicago[\"summer\"]).apply(np.log2)\n",
    "data.sort_values(by=\"winter_score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.to_string())\n",
    "data.to_csv(\"weather.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "becf0a720b843fdb863c837cbb6f5bf554c0ad94cf400ee9237b1b4690bf983a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ac10_podcast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
